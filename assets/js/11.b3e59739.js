(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{510:function(t,s,a){t.exports=a.p+"assets/img/redo-log.16a79502.png"},511:function(t,s,a){t.exports=a.p+"assets/img/b-tree.a5a2861b.jpg"},512:function(t,s,a){t.exports=a.p+"assets/img/b+tree.899dc3d2.jpg"},563:function(t,s,a){"use strict";a.r(s);var _=a(6),v=Object(_.a)({},(function(){var t=this,s=t.$createElement,_=t._self._c||s;return _("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[_("h2",{attrs:{id:"事务"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#事务"}},[t._v("#")]),t._v(" 事务")]),t._v(" "),_("ul",[_("li",[t._v("原子性, 事务是一个不可分割的最小单元, 一个事务的所有操作, 要么全部成功, 要么全部失败,")]),t._v(" "),_("li",[t._v("一致性, 数据库在事务执行的前后都保持一个一致的状态, 在一致性的状态下, 所有事务对一个数据的读取结果都是一致的,")]),t._v(" "),_("li",[t._v("隔离性, 事务在最终提交前, 对其他事务是不可见的,")]),t._v(" "),_("li",[t._v("持久性, 一个事务一旦执行成功, 则其所做的修改一定会保存到数据库中, 即便系统发生崩溃, 事务执行的结果也不能丢.")])]),t._v(" "),_("h2",{attrs:{id:"隔离级别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#隔离级别"}},[t._v("#")]),t._v(" 隔离级别")]),t._v(" "),_("ul",[_("li",[t._v("读未提交, 即一个事务还没有提交, 它做的变更就能被其他事务看到, 最低的隔离级别, 无法避免脏读, 不可重复读和幻读, 一般不使用,")]),t._v(" "),_("li",[t._v("读已提交, 即一个事务提交之后, 它做的变更才会被其他事务看到, 无法避免不可重复读和幻读,")]),t._v(" "),_("li",[t._v("可重复读, 即, 一个事务执行过程中看到的数据, 总是和这个事务启动时看到的数据是一直的, 无法避免幻读,\n"),_("ul",[_("li",[t._v("这里稍微解释下幻读, "),_("strong",[t._v("即在一个事务执行过程中, 看到了原本不存在的行")]),t._v(", 也就是说, 只有看到了新插入的行, 才能叫幻读,")]),t._v(" "),_("li",[t._v("InnoDB 通过 MVCC + (Next-Key Lock) 解决了幻读的问题.")])])]),t._v(" "),_("li",[t._v("串行化, 即对一个记录, 读会加读锁, 写会加写锁, 是最高的隔离级别, 性能会大幅度下降, 一般不推荐使用.")])]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",{staticStyle:{"text-align":"center"}},[t._v("隔离级别")]),t._v(" "),_("th",{staticStyle:{"text-align":"center"}},[t._v("脏读")]),t._v(" "),_("th",{staticStyle:{"text-align":"center"}},[t._v("不可重复读")]),t._v(" "),_("th",{staticStyle:{"text-align":"center"}},[t._v("幻影读")])])]),t._v(" "),_("tbody",[_("tr",[_("td",{staticStyle:{"text-align":"center"}},[t._v("未提交读")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("✅")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("✅")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("✅")])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"center"}},[t._v("提交读")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("❌")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("✅")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("✅")])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"center"}},[t._v("可重复读")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("❌")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("❌")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("✅")])]),t._v(" "),_("tr",[_("td",{staticStyle:{"text-align":"center"}},[t._v("可串行化")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("❌")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("❌")]),t._v(" "),_("td",{staticStyle:{"text-align":"center"}},[t._v("❌")])])])]),t._v(" "),_("p",[_("strong",[t._v("注: MySQL 默认的隔离级别是可重复读.")])]),t._v(" "),_("h2",{attrs:{id:"存储引擎"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#存储引擎"}},[t._v("#")]),t._v(" 存储引擎")]),t._v(" "),_("h3",{attrs:{id:"innodb"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#innodb"}},[t._v("#")]),t._v(" InnoDB")]),t._v(" "),_("ol",[_("li",[t._v("InnoDB 是现在 MySQL 默认使用的存储引擎, 它支持事务, 并且最小支持行锁, 支持的并发较高, 一般, 只有在使用它不提供的特性时, 才会考虑使用其他存储引擎,")]),t._v(" "),_("li",[t._v("InnoDB 采用 MVCC(即多版本并发控制) 来支持高并发, 它默认的隔离级别是可重复读, 在此隔离级别下, 通过 MVCC + Next-Key Lock 可以防止幻读,")]),t._v(" "),_("li",[t._v("InnoDB 采用B+树的数据结构来保存数据,\n"),_("ol",[_("li",[t._v("主键索引是聚簇索引, 在 B+ 树的叶子节点上保存了行的所有字段,")]),t._v(" "),_("li",[t._v("非主键索引是非聚簇索引, 在 B+ 树的叶子节点上保存了行的主键ID, 这也就是, 为什么根据非主键索引查询时, 可能(这里说可能, 是因为覆盖索引不需要回表)要二次回表的原因.")])])]),t._v(" "),_("li",[t._v("InnoDB 在其内部做了很多优化, 比如说从磁盘读取数据时, 采用了可预测性读, 能够在内存中创建hash索引(自适应hash索引)来加速读操作, 能够加速插入操作的插入缓冲区(changebuffer),")]),t._v(" "),_("li",[t._v("InnoDB 支持在线热备份.")])]),t._v(" "),_("h3",{attrs:{id:"myisam"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#myisam"}},[t._v("#")]),t._v(" MyISAM")]),t._v(" "),_("ol",[_("li",[t._v("数据以紧密格式存储, 对于只读数据, 小表来说, 依然可以考虑使用,")]),t._v(" "),_("li",[t._v("提供了一些特性, 比如说压缩表, 空间数据索引等,")]),t._v(" "),_("li",[t._v("不支持事务,")]),t._v(" "),_("li",[t._v("不支持行锁, 只能对整张表进行加锁, 读取会加读锁, 插入会加写锁, 但是在表有读取操作时, 也可以插入新的数据, 这就是并发插入.")])]),t._v(" "),_("h3",{attrs:{id:"对比"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#对比"}},[t._v("#")]),t._v(" 对比")]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",[t._v("存储引擎")]),t._v(" "),_("th",[t._v("InnoDB")]),t._v(" "),_("th",[t._v("MyISAM")])])]),t._v(" "),_("tbody",[_("tr",[_("td",[t._v("事务")]),t._v(" "),_("td",[t._v("✅")]),t._v(" "),_("td",[t._v("❌")])]),t._v(" "),_("tr",[_("td",[t._v("锁")]),t._v(" "),_("td",[t._v("支持表锁, 行锁.")]),t._v(" "),_("td",[t._v("只支持表锁.")])]),t._v(" "),_("tr",[_("td",[t._v("外键")]),t._v(" "),_("td",[t._v("✅")]),t._v(" "),_("td",[t._v("❌")])]),t._v(" "),_("tr",[_("td",[t._v("备份")]),t._v(" "),_("td",[t._v("支持在线热备份.")]),t._v(" "),_("td")]),t._v(" "),_("tr",[_("td",[t._v("崩溃恢复")]),t._v(" "),_("td"),t._v(" "),_("td",[t._v("崩溃损坏的概率高, 恢复慢.")])]),t._v(" "),_("tr",[_("td",[t._v("其他特性")]),t._v(" "),_("td"),t._v(" "),_("td",[t._v("支持压缩表, 空间数据索引.")])])])]),t._v(" "),_("h2",{attrs:{id:"日志模块"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#日志模块"}},[t._v("#")]),t._v(" 日志模块")]),t._v(" "),_("p",[t._v("MySQL 最终会将数据存储到磁盘上, 下面, 我们就来分析下 MySQL 的两个重要的日志模块.")]),t._v(" "),_("h3",{attrs:{id:"redo-log"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redo-log"}},[t._v("#")]),t._v(" redo log")]),t._v(" "),_("p",[t._v("在 MySQL 中, 如果每一次更新操作, 都需要写进磁盘, 那就涉及到要先找到对应的记录, 然后更新, 这整个过程的随机IO和查询成本很高, 所以, MySQL 就用到了"),_("strong",[t._v("WAL技术, 全称是Write-Ahead Logging")]),t._v(", 也就是先写日志, 再写磁盘.")]),t._v(" "),_("p",[t._v("具体的来说, 就是当有一条记录需要更新时, InnoDB 引擎会先将记录写到 redo log 里边, 然后更新内存, 就结束了. 在之后, InnoDB 会在适当的时候(一般都是系统比较空闲的时候), 将这个操作记录并更新到磁盘里.")]),t._v(" "),_("p",[t._v("与此同时, redo log 的大小是固定的, 比如说可以配置成一组4个文件, 每个文件1GB, 那就是一共有4GB可以使用, 整个 redo log, 可以当成一个环, 每次从头开始写, 写到末尾之后, 就又回到了开头, 如下图所示.")]),t._v(" "),_("p",[_("img",{attrs:{src:a(510),alt:"redo log"}})]),t._v(" "),_("p",[_("strong",[t._v("write pos")]),t._v("是当前记录的位置, 一边写一边向后移动,"),_("strong",[t._v("checkpoint")]),t._v("是当前要擦除的位置, 也是不停向后移动的, 在擦除记录前, 要把记录更新到数据文件, 也就是落盘. 一旦"),_("strong",[t._v("write pos")]),t._v("追上了"),_("strong",[t._v("checkpoint")]),t._v("的位置, 那就要先停下来擦除一些记录, 才能继续写入.")]),t._v(" "),_("p",[t._v("有了 redo log, InnoDB 就能保证, 即便数据库发生异常重启, 之前提交的记录也不会丢失, 这个能力称为 "),_("strong",[t._v("crash-safe")]),t._v(".")]),t._v(" "),_("h3",{attrs:{id:"binlog"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#binlog"}},[t._v("#")]),t._v(" binlog")]),t._v(" "),_("p",[t._v("MySQL 从整体上来看, 就分为两块, server 层和存储引擎层, 那上面讲到的redo log, 实际上是 InnoDB 特有的日志, 而 server 层也有自己的日志, 也就是"),_("strong",[t._v("binlog(归档日志)")]),t._v(".")]),t._v(" "),_("p",[t._v("这里多提一句, binlog有三种记录格式,")]),t._v(" "),_("ol",[_("li",[_("p",[_("code",[t._v("statement")]),t._v("格式记录的是 SQL 语句,")])]),t._v(" "),_("li",[_("p",[_("code",[t._v("row")]),t._v("格式会记录行的内容, 记两条, 更新前和更新后都有,")])]),t._v(" "),_("li",[_("p",[_("code",[t._v("mixed")]),t._v("格式, 其实就是上面两种格式的混合装,")]),t._v(" "),_("p",[t._v("因为"),_("code",[t._v("statement")]),t._v("可能会导致主备不一致, 而"),_("code",[t._v("row")]),t._v("格式又很占空间, 所以 MySQL 就取了个这种方案, 它会判断这个 SQL 语句会不会导致主备不一致, 如果会, 那就使用"),_("code",[t._v("row")]),t._v("格式, 如果不会, 那就使用"),_("code",[t._v("statement")]),t._v("格式.")])])]),t._v(" "),_("p",[t._v("一般, 在生产环境, 都建议将binlog格式设置为"),_("code",[t._v("row")]),t._v(", 它最直接的好处就是, 可以"),_("strong",[t._v("恢复数据")]),t._v(", 因为它记录的是更新前后的原数据.")]),t._v(" "),_("p",[t._v("可以使用如下配置, 设置binlog的格式为"),_("code",[t._v("row")]),t._v(".")]),t._v(" "),_("div",{staticClass:"language-SQL extra-class"},[_("pre",{pre:!0,attrs:{class:"language-sql"}},[_("code",[_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--- 将binlog的格式改成row")]),t._v("\nbinlog_format"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),_("span",{pre:!0,attrs:{class:"token string"}},[t._v("'row'")]),t._v("\n")])])]),_("h3",{attrs:{id:"对比-2"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#对比-2"}},[t._v("#")]),t._v(" 对比")]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",[t._v("redo log")]),t._v(" "),_("th",[t._v("binlog")])])]),t._v(" "),_("tbody",[_("tr",[_("td",[t._v("InnoDB 特有的")]),t._v(" "),_("td",[t._v("MySQL 在 server 层实现的, 所有引擎都可以使用")])]),t._v(" "),_("tr",[_("td",[t._v('物理日志, 记录的是"在某个数据页做了什么修改"')]),t._v(" "),_("td",[t._v("逻辑日志, 记录的是这个语句的原始逻辑, "),_("br"),t._v('比如说: "给ID=2这一行的c字段+1"')])]),t._v(" "),_("tr",[_("td",[t._v("循环写, 日志大小固定")]),t._v(" "),_("td",[t._v("追加写, 当一个 binlog 文件写到一定大小之后, 会切换下一个")])])])]),t._v(" "),_("h3",{attrs:{id:"更新语句的执行过程"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#更新语句的执行过程"}},[t._v("#")]),t._v(" 更新语句的执行过程")]),t._v(" "),_("p",[t._v("假设有下面这样一行更新语句, MySQL 是如何执行的.")]),t._v(" "),_("div",{staticClass:"language-SQL extra-class"},[_("pre",{pre:!0,attrs:{class:"language-sql"}},[_("code",[_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),t._v(" T "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" c"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" id"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n")])])]),_("ol",[_("li",[t._v("执行器先找 InnoDB 获取id=2的这一行, 因为id是主键, 所以InnoDB 用树搜索查找到这一行, 如果这一行的数据页在内存中, 直接返回, 如果不在, 则需要先从磁盘读入内存, 然后再返回,")]),t._v(" "),_("li",[t._v("执行器拿到这行数据, 把c+1, 然后再调用 InnoDB 接口写入这行新数据,")]),t._v(" "),_("li",[t._v("InnoDB 将这行数据更新到内存中, 并记录到redo log, 此时redo log处于"),_("strong",[t._v("prepare")]),t._v("状态, 再告知执行器操作完成, 可以提交事务,")]),t._v(" "),_("li",[t._v("执行器生成这个操作的 binlog, 并将binlog写入磁盘,")]),t._v(" "),_("li",[t._v("执行器调用 InnoDB 的提交事务接口, 将刚才的redo log改成"),_("strong",[t._v("commit")]),t._v("状态,")]),t._v(" "),_("li",[t._v("更新结束.")])]),t._v(" "),_("p",[t._v("这里, 就是典型的"),_("strong",[t._v("两阶段提交")]),t._v("了, 使用它的目的, 就是为了避免 MySQL 异常宕机导致数据丢失的情况.")]),t._v(" "),_("p",[t._v("在上面分析的过程, 可以看到, 实际上是有两次写盘操作的, 而WAL 机制又说是为了减少磁盘写, 那它的优势在哪呢?")]),t._v(" "),_("ol",[_("li",[t._v("其实很简单, 因为 redo log 和 binlog 都是"),_("strong",[t._v("顺序写")]),t._v(", 而磁盘的顺序写比随机写要快很多,")]),t._v(" "),_("li",[t._v("另外还有个"),_("strong",[t._v("组提交机制")]),t._v("也大幅度的降低了磁盘的IOPS消耗.")])]),t._v(" "),_("h3",{attrs:{id:"配置"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#配置"}},[t._v("#")]),t._v(" 配置")]),t._v(" "),_("p",[t._v("MySQL 提供了两个配置参数, 建议都设置为1, 这样可以保证MySQL 异常重启后, 数据不会丢失.")]),t._v(" "),_("div",{staticClass:"language-sql extra-class"},[_("pre",{pre:!0,attrs:{class:"language-sql"}},[_("code",[_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--- 配置为0, 表示每次事务提交时, 只把redo log留在redo log buffer中")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--- 配置为1, 表示每次事务提交时, 都要把redo log持久化到磁盘")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--- 配置为2时, 表示每次事务提交时, 只把redo log写到page cache")]),t._v("\ninnodb_flush_log_at_trx_commit"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--- 配置为0, 表示每次事务提交时, 只write, 不fsync")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--- 配置为1, 表示每次事务提交时, 即write, 还要fsync, 也就是说将binlog持久化到磁盘")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--- 配置成N(N>1)时, 表示每次事务提交时, 只write, 累计N个事务后再近些fsybc")]),t._v("\nsync_binlog"),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),_("h2",{attrs:{id:"索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#索引"}},[t._v("#")]),t._v(" 索引")]),t._v(" "),_("p",[t._v("MySQL 的索引是在存储引擎层实现的.")]),t._v(" "),_("h3",{attrs:{id:"b-tree-索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#b-tree-索引"}},[t._v("#")]),t._v(" B+ Tree 索引")]),t._v(" "),_("ul",[_("li",[t._v("有序, 除了查询还可以进行排序和分组,")]),t._v(" "),_("li",[t._v("可以指定多个列作为索引键, 即联合索引,")]),t._v(" "),_("li",[t._v("支持全键值, 键值范围和键前缀查找(最左前缀),")]),t._v(" "),_("li",[t._v("全表扫描只需要遍历主键索引树的所有叶子节点即可,")]),t._v(" "),_("li",[t._v("查询复杂度稳定, 因为数据都保存在主键索引的叶子节点上, 索引无论查询条件是什么, 最终都会遍历完主键索引树的所有层级.")])]),t._v(" "),_("h3",{attrs:{id:"哈希索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#哈希索引"}},[t._v("#")]),t._v(" 哈希索引")]),t._v(" "),_("ul",[_("li",[t._v("支持O(1)的查询时间复杂度, 但是只支持精确查找, 无法用于部分查找, 范围查找, 更没办法进行排序和分组.")])]),t._v(" "),_("h3",{attrs:{id:"全文索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#全文索引"}},[t._v("#")]),t._v(" 全文索引")]),t._v(" "),_("ul",[_("li",[t._v("myisam存储引擎支持全文索引, 用于查找文本中的关键词, 而不是直接匹配是否相等, 查找条件使用的是 MATCH AGAINST, 全文索引使用"),_("strong",[t._v("倒排索引")]),t._v("实现, 记录了关键词到文档的映射,")]),t._v(" "),_("li",[t._v("InnoDB 在MySQL 5.6.4之后也开始支持全文索引.")])]),t._v(" "),_("h3",{attrs:{id:"聚簇索引和非聚簇索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#聚簇索引和非聚簇索引"}},[t._v("#")]),t._v(" 聚簇索引和非聚簇索引")]),t._v(" "),_("p",[t._v("InnoDB 存储引擎是通过索引树来保存数据的.")]),t._v(" "),_("p",[t._v("聚簇索引也就是常说的主键索引, 即该索引树的叶子节点保存了数据行的完整数据,")]),t._v(" "),_("p",[t._v("非聚簇索引也叫辅助索引, 即该索引树的叶子节点保存的是数据行的主键ID, 当索引树没有查询的列时, 需要回表(到主键索引树)二次查询.")]),t._v(" "),_("p",[t._v("InnoDB 的主键索引的定义规则如下,")]),t._v(" "),_("ol",[_("li",[t._v("在表上定义主键PRIMARY KEY, InnoDB将主键索引用作聚簇索引,")]),t._v(" "),_("li",[t._v("如果表没有定义主键, InnoDB 会选择第一个不为NULL的唯一索引列用作聚簇索引,")]),t._v(" "),_("li",[t._v("如果以上两个都没有, InnoDB 会使用一个6 字节长整型的隐式字段 ROWID字段构建聚簇索引, 该ROWID字段会在插入新行时自动递增.")])]),t._v(" "),_("h3",{attrs:{id:"唯一索引和普通索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#唯一索引和普通索引"}},[t._v("#")]),t._v(" 唯一索引和普通索引")]),t._v(" "),_("p",[t._v("唯一索引就是说在索引树上, 只会一条相同索引, 如果再次插入相同索引时, 会报错, 即可以保证索引的唯一性, 而普通索引就没有这个限制.")]),t._v(" "),_("p",[t._v("那应该选择唯一索引还是普通索引呢? 我们从两个方面来分析,")]),t._v(" "),_("h4",{attrs:{id:"查询时"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#查询时"}},[t._v("#")]),t._v(" 查询时")]),t._v(" "),_("ol",[_("li",[_("p",[t._v("对于普通索引来说, 查到满足条件的第一个记录后, 还需要查询下一个记录, 直到返回的记录不满足条件, 才会停止检索,")])]),t._v(" "),_("li",[_("p",[t._v("而对于唯一索引来说, 查到满足条件的第一个记录后, 就会停止检索.")])])]),t._v(" "),_("p",[t._v("那表面上看, "),_("s",[t._v("貌似唯一索引会比普通索引更快")]),t._v(", 但是实际上, "),_("strong",[t._v("MySQL在读取数据是按页读取的")]),t._v(", 也就是说, 当需要读取一条记录时, 并不是将这条记录从磁盘上读出, 而是以页为单位, 将整个数据页读入内存, 而InnoDB每个数据页的大小, 默认是16KB.")]),t._v(" "),_("p",[t._v("那这么看来, 普通索引在检索下一条记录时, 实际上就是内存的读取了, 速度是相当快的; 即便是极端情况, 某个普通索引有很多记录, 导致跨页了, 也只是稍微慢了一点,")]),t._v(" "),_("p",[t._v("而且, 假设对于整型字段来说, 一个数据页就可以放下近千个索引, 所以, 相同索引跨页的这种概率, 实际上是很低的.")]),t._v(" "),_("p",[_("strong",[t._v("所以, 我们可以认为, 普通索引和唯一索引, 在读取操作的性能上基本没有区别.")])]),t._v(" "),_("h4",{attrs:{id:"更新时"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#更新时"}},[t._v("#")]),t._v(" 更新时")]),t._v(" "),_("p",[t._v("提到更新, 那就要先说一说"),_("strong",[t._v("changebuffer")]),t._v("的概念,")]),t._v(" "),_("h5",{attrs:{id:"changebuffer"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#changebuffer"}},[t._v("#")]),t._v(" changebuffer")]),t._v(" "),_("p",[t._v("当需要更新一个数据页时, 如果该数据页在内存中, 那就会直接更新; 如果这个数据页不在内存中, 在不影响数据一致性的前提下, InnoDB会将这些更新缓存到changebuffer中, 这样, 就不需要从磁盘读取这个数据页了. 当下一次读取这个数据页时, 再执行changebuffer中与这个数据页相关的操作.")]),t._v(" "),_("p",[t._v("并且, changebuffer也是可以持久化的, 即changebuffer在内存中有拷贝, 也会被写到磁盘上, 这样也就避免了MySQL异常宕机时更新丢失.")]),t._v(" "),_("p",[t._v("那将changebuffer的更新应用到数据页的过程称为"),_("strong",[t._v("merge")]),t._v(", 除了访问该数据页会有merge外, MySQL也有后台线程进行定期merge, 在数据库关闭时, 也会进行merge.")]),t._v(" "),_("p",[t._v("所以, 将更新先缓存到changebuffer中, 就减少了读磁盘, 提高了语句的执行速度, 并且, 因为将数据页读入内存是需要占用"),_("strong",[t._v("buffer pool")]),t._v("的空间了, 那changebuffer还能避免占用空间, 提搞内存的利用率.")]),t._v(" "),_("p",[t._v("changebuffer讲完了, 我们再回过头来看唯一索引, 既然是唯一的, 那所有的更新操作都需要判断索引的唯一性, 那就必须将数据页读入内存才能判断, 数据已经读入内存了, 那更新肯定是直接执行了, 就用不到changebuffer了,")]),t._v(" "),_("p",[t._v("反之, 对于普通索引来说, 不需要判断唯一性, 也就不需要读取数据页, 当数据页不在内存中时, 就可以将更新缓存到changebuffer, 直接返回.")]),t._v(" "),_("p",[t._v("那这里可以举个栗子, 当需要在表中插入一条新纪录时,")]),t._v(" "),_("ol",[_("li",[t._v("如果这个记录要更新的数据页在内存中,\n"),_("ol",[_("li",[t._v("对于唯一索引来说, 判断有没有相同索引, 若没有, 直接插入, 语句执行结束,")]),t._v(" "),_("li",[t._v("对于普通索引来说, 直接找到对应位置插入, 语句执行结束.")])])]),t._v(" "),_("li",[t._v("如果这个记录要更新的数据页不在内存中,\n"),_("ol",[_("li",[t._v("对于唯一索引来说, 需要先将数据页读入内存, 然后再执行1.1的操作,")]),t._v(" "),_("li",[t._v("对于普通索引来说, 直接将更新写入changebuffer, 语句执行结束.")])])])]),t._v(" "),_("p",[t._v("将数据页从磁盘读入内存, 涉及到随机IO, 是数据库成本最高的操作之一了, 而changebuffer减少了磁盘的随机访问, 对于更新操作的性能提升是很明显的.")]),t._v(" "),_("p",[_("strong",[t._v("所以, 我们可以认为, 在多数情况下, 普通索引相对于唯一索引, 在更新操作上, 性能更好.")])]),t._v(" "),_("p",[t._v("不过, changebuffer也不是万能的, 比如说, 更新之后, 立马就要读取这个数据页, 那就会直接触发merge动作, 这就导致, 不仅没有降低磁盘的随机访问IO, 还增加了changebuffer的维护成本.")]),t._v(" "),_("h4",{attrs:{id:"小结"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),_("p",[t._v("这里, 就可以得出两条结论,")]),t._v(" "),_("ol",[_("li",[t._v("如果可用通过应用程序保证字段的唯一性, 那就优先选择普通索引, 因为更新的性能更好,")]),t._v(" "),_("li",[t._v("但是, 如果在更新之后, 直接就要读取这个数据页, 可以考虑关闭changebuffer, 在其他情况下, changebuffer都能提高更新的性能.")])]),t._v(" "),_("h3",{attrs:{id:"页分裂-页合并"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#页分裂-页合并"}},[t._v("#")]),t._v(" 页分裂, 页合并")]),t._v(" "),_("p",[t._v("InnoDB 保存数据的最小单位是页(page), 默认大小是16K,")]),t._v(" "),_("h4",{attrs:{id:"页分裂"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#页分裂"}},[t._v("#")]),t._v(" 页分裂")]),t._v(" "),_("p",[t._v("上面提到, 页的大小默认是16K, 那就总会有用完的时候, 当索引插入时, 如果判断到当前页满了,而恰好下一个页也满了, 这个时候, InnoDB 就会执行如下操作,")]),t._v(" "),_("ol",[_("li",[t._v("创建一个新页,")]),t._v(" "),_("li",[t._v("找到当前页应该分裂的位置(按数据行算),")]),t._v(" "),_("li",[t._v("将这些数据移动到新页,")]),t._v(" "),_("li",[t._v("将索引插入到合适的位置,")]),t._v(" "),_("li",[t._v("重新定义页之间的指向关系.")])]),t._v(" "),_("p",[t._v("此时, B+ 树的路径在逻辑上是连续的, 但是物理上, 页是无序的.")]),t._v(" "),_("p",[t._v("一旦发生页分裂, 就只能通过下面的页合并逻辑触发来恢复了, 当然, 也可以通过OPTIMIZE优化表结构来触发, 只不过比较浪费资源罢了.")]),t._v(" "),_("h4",{attrs:{id:"页合并"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#页合并"}},[t._v("#")]),t._v(" 页合并")]),t._v(" "),_("p",[t._v("页有个重要的属性, MERGE_THRESHOLD(默认值是50, 即50%, 可设置的范围是1-50).")]),t._v(" "),_("p",[t._v("在多次执行删除操作后, 如果(某个数据页的数据量/数据页的大小)<阈值(即上面的MERGE_THRESHOLD)时, InnoDB 就会检查该页相邻的两个页的数据量, 判断是否可以执行合并操作, 如果有某个页的数据量也小于MERGE_THRESHOLD, 那InnoDB就会执行合并操作, 将两个页的数据合并到一个页上, 将另一个页置空, 留待使用.")]),t._v(" "),_("h3",{attrs:{id:"索引优化"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#索引优化"}},[t._v("#")]),t._v(" 索引优化")]),t._v(" "),_("ul",[_("li",[_("p",[t._v("在进行查询时, 索引列不能是表达式的一部分, 也不能是函数的参数, 也不能是前缀模糊查询, 否则无法使用索引,")])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("覆盖索引")]),t._v(", 即索引树包含了想要查询的所有列, 这种情况下, InnoDB 不需要二次回表查询; 并且, 索引通常小于数据行的大小, 只读取索引能大大减少数据的访问量; 还有一些存储引擎(如myisam), 在内存中只缓存索引, 这种情况下, 可以避免系统调用,")])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("索引下推")]),t._v(", 在MySQL 5.6之后, 引入了索引下推优化, 即在索引遍历过程中, 会先对索引中包含的字段做判断, 直接过滤掉不满足条件的行, 减少回表的次数.,")])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("联合索引")]),t._v(", 如果查询时会根据多列进行搜索, 可以考虑建立联合索引, 同时, 将选择性最强的列放到前面,")])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("前缀索引")]),t._v(", 对于blob, text, varchar等类型的列来说, 必须使用前缀索引, 即只索引开始部分的字符, 同时, 前缀索引的长度, 也需要根据字符内容的选择性进行决定,")]),t._v(" "),_("p",[t._v("索引的选择性指的是, 不重复的索引值/记录总数=m, m最大为1, 那m越大时, 选择性越强, 下面给出一个简单的示例, 来判断字段的选择性和字段前缀长度的的选择性.")]),t._v(" "),_("div",{staticClass:"language-sql extra-class"},[_("pre",{pre:!0,attrs:{class:"language-sql"}},[_("code",[_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n\t"),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DISTINCT")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" name "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("COUNT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" all_char"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DISTINCT")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("COUNT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("_char"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DISTINCT")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("COUNT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("_char"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DISTINCT")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("COUNT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("_char"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DISTINCT")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("COUNT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("_char"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),_("span",{pre:!0,attrs:{class:"token function"}},[t._v("COUNT")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" all_count\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v("\n\ttest\n")])])])]),t._v(" "),_("li",[_("p",[_("strong",[t._v("最左前缀匹配")]),t._v(", MySQL 会一直向右匹配索引直到遇到范围查询(>, <, between, like), =和in都可以乱序执行, 比如说建立了索引(a,b,c), 那语句"),_("code",[t._v("select * from where c=1 and b=2 and a=3")]),t._v("一样可以使用索引,")])]),t._v(" "),_("li",[_("p",[t._v("尽量选择扩展索引, 而不是新建索引.")])])]),t._v(" "),_("h3",{attrs:{id:"索引的优点"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#索引的优点"}},[t._v("#")]),t._v(" 索引的优点")]),t._v(" "),_("ul",[_("li",[t._v("大大减少的服务器需要扫描的数据行,")]),t._v(" "),_("li",[t._v("将随机IO变成了顺序IO, 因为B+ 树索引是有序的, 会将相邻的元素保存到一个数据页.")])]),t._v(" "),_("h3",{attrs:{id:"索引的使用条件"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#索引的使用条件"}},[t._v("#")]),t._v(" 索引的使用条件")]),t._v(" "),_("ul",[_("li",[t._v("对于比较小的表, 可能全表扫描要比建立索引更高效, 因为, 根据索引查询, 如果不满足覆盖索引的前提, 需要二次回表查询,")]),t._v(" "),_("li",[t._v("对于中到大型表, 建立索引的优势比较大,")]),t._v(" "),_("li",[t._v("对于超大型的表, 建立和维护索引的代价也会随之增长, 所以更好的办法是进行拆分表.")])]),t._v(" "),_("h3",{attrs:{id:"为什么-innodb-选用-b-树"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#为什么-innodb-选用-b-树"}},[t._v("#")]),t._v(" 为什么 InnoDB 选用 B+ 树")]),t._v(" "),_("h4",{attrs:{id:"常见的数据结构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#常见的数据结构"}},[t._v("#")]),t._v(" 常见的数据结构")]),t._v(" "),_("h5",{attrs:{id:"哈希"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#哈希"}},[t._v("#")]),t._v(" 哈希")]),t._v(" "),_("p",[t._v("hash 很简单, 像hashmap就是hash的数据结构, 以键值对的方式保存数据, 时间复杂度为O(1),")]),t._v(" "),_("p",[t._v("但是, 缺点也很明显, 就是只支持精确查找, 想模糊查找, 范围查找, 都只能通过全表扫描来实现.")]),t._v(" "),_("p",[t._v("所以在 MySQL 中只有 Memory 引擎支持hash索引("),_("s",[t._v("InnoDB的自适应hash不在讨论范围内, 因为没有办法手动设置")]),t._v("), 场景单一.")]),t._v(" "),_("h5",{attrs:{id:"数组"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数组"}},[t._v("#")]),t._v(" 数组")]),t._v(" "),_("p",[t._v("数组就是一块连续的空间, 根据下标查询速度很快, 可以访问指定位置的元素内容, 但是同样, 它也只支持精确查找和范围查找, 想要模糊查找的话也只能全表扫描, 而且, 由于它是一块连续的空间, 插入时需要将指定位置之后的元素都向后移动, 才能插入, 所以它的查询效率高, 但是插入, 删除的效率很低.")]),t._v(" "),_("h5",{attrs:{id:"avl-树"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#avl-树"}},[t._v("#")]),t._v(" AVL 树")]),t._v(" "),_("p",[t._v("平衡二叉树, 它最主要的特点是, 左右子树的层级最多相差1, 当插入或者删除数据的时候, 会通过"),_("strong",[t._v("左旋右旋")]),t._v("来保证树的平衡, 所以它的查询性能接近于二分查找, 也就是O(log2n), 但是它的插入, 删除会比较慢.")]),t._v(" "),_("p",[t._v("但是, 因为 MySQL 的数据是持久化到磁盘上的, 而每个树节点的读取都涉及到一次磁盘IO, 所以树的高度, 就等于检索的次数, 那在表数据量很大的情况下, 它的性能就会很差.")]),t._v(" "),_("h5",{attrs:{id:"红黑树"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#红黑树"}},[t._v("#")]),t._v(" 红黑树")]),t._v(" "),_("p",[t._v("红黑树和AVL树一样, 都是对二叉搜索树的改进版, 不同的地方在于,")]),t._v(" "),_("ol",[_("li",[t._v("红黑树给树的每个节点都标了颜色, 即red或者black,")]),t._v(" "),_("li",[t._v("并且, 红黑树不像AVL树那样要求极端平衡, 红黑树只要求不会存在一条路径比其他路径长2倍, 所以它是近似平衡的,")]),t._v(" "),_("li",[t._v("红黑树在AVL树的"),_("strong",[t._v("左旋右旋")]),t._v("的基础上, 又添加了"),_("strong",[t._v("着色")]),t._v(", 因为左旋右旋涉及到树节点的变动, 而着色只是对节点属性的变更, 所以它的插入, 删除更快, 但是查询相对于AVL 树来说, 会比较慢.")])]),t._v(" "),_("p",[t._v("下面列举一下红黑树的特性,")]),t._v(" "),_("ol",[_("li",[t._v("每个结点的颜色只能是红色或黑色的,")]),t._v(" "),_("li",[t._v("根结点是黑色的,")]),t._v(" "),_("li",[t._v("每个叶子结点(NIL)是黑色的,")]),t._v(" "),_("li",[t._v("如果一个结点是红色的, 那么它的两个子结点都是黑色的,")]),t._v(" "),_("li",[t._v("对每个结点来说, 从该结点到其所有后代叶子节点的简单路径上, 均包含相同数目的黑色结点.")])]),t._v(" "),_("p",[t._v("那红黑树的问题, 其实和AVL 树的问题类似, 在查询的时候, 每个树节点的读取都涉及到一次磁盘IO, 所以树的高度, 就等于检索的次数, 那在表数据量很大的情况下, 它的性能就会很差.")]),t._v(" "),_("h5",{attrs:{id:"b-树"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#b-树"}},[t._v("#")]),t._v(" B 树")]),t._v(" "),_("p",[t._v("考虑到MySQL 的数据是按页存储的, 而且每次读取数据都是将整个数据页读入内存, 那每页只存储一个节点数据是十分浪费的, 所以就将二叉树改造成了多叉树(每个节点存储了多个数据, 并且有多个分叉, 其目的就是为了降低树的深度), 也就是B 树.")]),t._v(" "),_("p",[t._v("下面列举一下B 树的特性,")]),t._v(" "),_("ol",[_("li",[t._v("B 树的每个节点都存储了多个元素, 并且非叶子节点都有多个分叉,")]),t._v(" "),_("li",[t._v("节点中的元素包含了键值和数据, 按照键值从大到小排列, 也就是说, "),_("strong",[t._v("每个节点都会用来存储数据")]),t._v(",")]),t._v(" "),_("li",[t._v("父节点的元素不会出现在子节点中,")]),t._v(" "),_("li",[t._v("所有叶子节点都位于同一层, 叶子节点具有相同的深度, 并且没有指针相互连接.")])]),t._v(" "),_("p",[t._v("下面借一张敖丙的图来展示 B 树的基本结构,")]),t._v(" "),_("p",[_("img",{attrs:{src:a(511),alt:"B Tree"}})]),t._v(" "),_("p",[t._v("那B 树的问题在于什么呢?")]),t._v(" "),_("ol",[_("li",[t._v("因为B 树在非叶子节点和叶子节点上都会保存数据, 这就导致, 如果某一张表的字段很多, 一行记录所占的空间就会增大, 非叶子节点存储的记录数就会减少, 同样也会增加树高, 也就会导致磁盘的IO次数增加,")]),t._v(" "),_("li",[t._v("B 树不支持范围查找, 因为数据存储在不同的节点上, 而节点之间又没有指针联系, 所以要查找一个范围内的数据, 就要每次都回到主节点重新进行检索, 查询效率就会降低.")])]),t._v(" "),_("h5",{attrs:{id:"b-树-2"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#b-树-2"}},[t._v("#")]),t._v(" B+ 树")]),t._v(" "),_("p",[t._v("B+ 树, 节点有序, 只有叶子节点会保存数据, 非叶子节点只会保存键值, 并且叶子节点之间使用双向指针进行连接, 形成了一个双向链表.")]),t._v(" "),_("p",[t._v("下面借一张敖丙的图来展示 B +树的基本结构,")]),t._v(" "),_("p",[_("img",{attrs:{src:a(512),alt:"B+ Tree"}})]),t._v(" "),_("p",[t._v("那 B + 树的优势有哪些呢?")]),t._v(" "),_("ol",[_("li",[_("p",[t._v("由于非叶子节点只保存键值, 不存储数据, 那相对于B 树来说, 单个数据页能容纳的数据就会比较多, 树的高度就会变矮, 就可以降低磁盘IO,")])]),t._v(" "),_("li",[_("p",[t._v("和B 树一样, 支持等值查询, 虽然要读取到树的叶子节点才能得到记录的完整数据, 但是配合优化1, 二者的性能基本差不多,")])]),t._v(" "),_("li",[_("p",[t._v("由于叶子节点之间有双向指针连接, 所以可以很好的支持范围查询,")]),t._v(" "),_("p",[t._v("举个栗子, 假设要查询id在5-20之间的数据, 那就可以先按照等值查询, 查找到id=5的节点位置, 然后顺序向后遍历叶子节点中的数据, 直到找到id=20的记录(这里因为id是主键, 所以查到id=20就可以返回了), 就可返回数据.")])]),t._v(" "),_("li",[_("p",[t._v("所有数据都保存在叶子节点, 无论查询什么数据, 最后都要读取到树的最后一层(当然, 如果是覆盖索引的话, 就无须读取到叶子节点, 查询到数据直接返回即可), 查询性能比较稳定.")])])]),t._v(" "),_("h2",{attrs:{id:"mvcc"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mvcc"}},[t._v("#")]),t._v(" MVCC")]),t._v(" "),_("p",[t._v("上文多次提到了MVCC, 那它的全称是"),_("strong",[t._v("多版本并发控制")]),t._v(", 是 InnoDB 实现隔离级别的一种方式, 它用于实现已提交读和可重复读这两种, 未提交读总是读取数据最新的行, 无需使用MVCC, 而串行化是通过加锁来实现的.")]),t._v(" "),_("p",[t._v("在实现上, MVCC会在需要的时候, 创建一个一致性视图(read-view), 访问数据时, 都以视图的逻辑结果为准,")]),t._v(" "),_("ol",[_("li",[t._v("对于"),_("strong",[t._v("读提交")]),t._v("来说, 一致性视图是在每个SQL语句开始执行的时候创建的,")]),t._v(" "),_("li",[t._v("对于"),_("strong",[t._v("可重复读")]),t._v("来说, 一致性视图是在事务启动的时候创建的, 整个事务执行期间, 都用这一个视图.")])]),t._v(" "),_("h3",{attrs:{id:"一致性视图"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#一致性视图"}},[t._v("#")]),t._v(" 一致性视图")]),t._v(" "),_("p",[t._v("首先, InnoDB 中有一个事务ID, 叫做"),_("code",[t._v("transaction id")]),t._v(", 它是事务在启动是向系统申请的, 是严格递增的,")]),t._v(" "),_("p",[t._v("然后, 在InnoDB 中, 每个数据行都有多个数据版本, 每次事务更新数据时, 都会生成一个新的数据版本, 并把上面的"),_("code",[t._v("transaction id")]),t._v("赋值给这个数据版本的事务ID, 即"),_("code",[t._v("row trx_id")]),t._v(", 同时, 旧的数据版本会保留, 在新的数据版本中, 也可以拿到它.")]),t._v(" "),_("p",[t._v("这也就是说, 一个数据行是可能有多个版本的, 并且每个版本都有自己的"),_("code",[t._v("row trx_id")]),t._v(". 这里就引入了一个新的概念, "),_("strong",[t._v("undo log(回滚日志)")]),t._v(", 即数据库记录了数据行的更新操作, 如果需要回滚到旧的row版本, 会依次反向执行更新, 进而恢复到以前的row版本.")]),t._v(" "),_("p",[t._v('那在可重复读级别下, 事务在启动的时候, 就"拍了个快照", 这个快照是基于整库的, 那快照实际上就是通过将事务启动时, 所有活跃的事务ID保存到一个数组中, 这里的"活跃", 就是说启动了还没提交. 然后, 将数组中的最小值, 记为低水位, 将当前已创建的最大的事务ID+1, 记为高水位, 这个数组和高水位就构成了一个一致性视图, 而数据的可见性, 就是将数据的'),_("code",[t._v("row trx_id")]),t._v("和这个一致性数图进行比较.")]),t._v(" "),_("p",[t._v("那这里, 我们直接总结下,")]),t._v(" "),_("p",[t._v("一个数据版本, 对于一个事务视图来说, 除了自己的更新总是可见以外, 有三种情况:")]),t._v(" "),_("ol",[_("li",[t._v("版本未提交, 不可见,")]),t._v(" "),_("li",[t._v("版本已提交, 但是是在视图创建后提交的, 不可见,")]),t._v(" "),_("li",[t._v("版本已提交, 是在视图创建前提交的, 可见.")])]),t._v(" "),_("p",[t._v("除此之外, 这里还有一条规则, 就是"),_("strong",[t._v("每次更新操作, 都是先读后写的, 而这个读, 只能读当前最新的数据, 称为当前读(current read)")]),t._v(", 那当前读, 就是会读到数据的最新值, 而不是一致性视图中的数据版本.")]),t._v(" "),_("p",[t._v("那除了 update 语句之外, 也可以通过在"),_("code",[t._v("select")]),t._v("语句后加"),_("code",[t._v("lock in shard mode")]),t._v("(读锁)或者"),_("code",[t._v("for update")]),t._v("(写锁), 开启当前读.")]),t._v(" "),_("p",[t._v("到这里, 就把一致性视图, 当前读和行锁串联起来了, 总的来说, "),_("strong",[t._v("可重复读的核心就是一致性读, 而事务更新数据时, 只能用当前读, 如果当前记录的行锁被其他事务占用的话, 就必须进入锁等待")]),t._v(".")]),t._v(" "),_("p",[t._v("而读提交的逻辑和可重复读类似, 二者的区别是,")]),t._v(" "),_("ul",[_("li",[t._v("在可重复读隔离级别下, 只需要在事务开始的时候创建一致性视图, 之后事务里的其他查询都共用这个一致性视图,")]),t._v(" "),_("li",[t._v("在读提交隔离级别下, 每一个语句执行前都会重新算出一个新的视图,")]),t._v(" "),_("li",[t._v("并且, 在读提交隔离级别下, "),_("code",[t._v("start transaction with consistent snapshot")]),t._v("就等同于"),_("code",[t._v("start transaction")]),t._v(", 因为它是在每个语句执行前重新生成一个视图.")])]),t._v(" "),_("p",[t._v("小结一下,")]),t._v(" "),_("ul",[_("li",[t._v("对于可重复读, 查询只承认在事务启动前就提交完成的数据,")]),t._v(" "),_("li",[t._v("对于读提交, 查询只承认在语句执行前就提交完成的数据,")]),t._v(" "),_("li",[t._v("而对于当前读, 总是读取数据已经提交完成的最新版本.")])]),t._v(" "),_("h3",{attrs:{id:"事务是何时启动的"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#事务是何时启动的"}},[t._v("#")]),t._v(" 事务是何时启动的")]),t._v(" "),_("p",[_("strong",[t._v("如果没有特殊说明, 下面都是在autocommit=1的基础上进行分析.")])]),t._v(" "),_("p",[t._v("显式的启动事务有两种方式,")]),t._v(" "),_("ul",[_("li",[_("code",[t._v("begin/start transaction")]),t._v(", 需要注意的是, 这个语句并不是事务的起点, 只有在其之后执行的第一个语句, 才会真正的启动事务, 也就是说, 一致性视图, 是在执行第一个语句的时候创建的.")]),t._v(" "),_("li",[_("code",[t._v("start transaction with consistent snapshot")]),t._v(", 这个语句会马上启动一个事务, 也就是说, 一致性视图, 是在执行该语句的时候创建的.")])]),t._v(" "),_("h2",{attrs:{id:"锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#锁"}},[t._v("#")]),t._v(" 锁")]),t._v(" "),_("p",[t._v("因为 InnoDB 是 MySQL 默认的存储引擎, 也是使用最多的, 所以下面主要分析 InnoDB 的锁.")]),t._v(" "),_("h3",{attrs:{id:"锁的分类"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#锁的分类"}},[t._v("#")]),t._v(" 锁的分类")]),t._v(" "),_("ul",[_("li",[t._v("读锁/共享锁(S Lock), 允许事务读一行数据,")]),t._v(" "),_("li",[t._v("写锁/排它锁(X Lock), 允许事务删除或者更新一行数据,")]),t._v(" "),_("li",[t._v("意向共享锁(IS Lock), 事务想要获得一张表中某几行的共享锁,")]),t._v(" "),_("li",[t._v("意向排它锁, 事务想获取一个表中某几行的排它锁.")])]),t._v(" "),_("h4",{attrs:{id:"全局锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#全局锁"}},[t._v("#")]),t._v(" 全局锁")]),t._v(" "),_("p",[t._v("全局锁, 就是对整个数据库实例进行加锁, MySQL提供了一个加全局读锁的命令, 即 "),_("code",[t._v("Flush tables with read lock (FTWRL)")]),t._v(", 使用这个命令后, 其他的数据更新语句, 数据定义语句, 更新类事务的提交语句都会被阻塞.")]),t._v(" "),_("p",[_("strong",[t._v("那全局锁的典型应用场景, 就是做全库逻辑备份.")]),t._v(" 但是, 让全库只读的风险是很大的, 比如说, 如果是在主库备份, 就会导致所有的业务停摆; 如果是在从库备份, 就会导致较长的主从延迟, 那如何解决呢?")]),t._v(" "),_("p",[t._v("这个时候, 就是MVCC出场的时候了, 上文有提到, 在可重复读隔离级别下, 开启事务可以生成一个一致性视图, 而且不会影响其他事务的执行.")]),t._v(" "),_("p",[t._v("那MySQL自带的mysqldump逻辑备份工具, 其实就是这么实现的, 当"),_("code",[t._v("mysqldump")]),t._v("使用参数"),_("code",[t._v("-single-transaction")]),t._v("时, 就会在导出数据前, 开启事务, 拿到一个一致性视图, 进而就可以在逻辑备份的同时, 也不影响其他线程的更新操作.")]),t._v(" "),_("p",[t._v("但是请注意, "),_("code",[t._v("-single-transaction")]),t._v("参数"),_("strong",[t._v("只适用于所有的表都使用了事务引擎(目前应该只有InnoDB)的库")]),t._v(".")]),t._v(" "),_("h4",{attrs:{id:"表级锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#表级锁"}},[t._v("#")]),t._v(" 表级锁")]),t._v(" "),_("p",[t._v("表级锁分为两种, 即表锁和MDL锁.")]),t._v(" "),_("h5",{attrs:{id:"表锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#表锁"}},[t._v("#")]),t._v(" 表锁")]),t._v(" "),_("p",[t._v("可通过"),_("code",[t._v("lock tables … read/write")]),t._v("开启表锁, 和"),_("code",[t._v("FTWRL")]),t._v("类似, 可以通过"),_("code",[t._v("unlock tables")]),t._v("释放锁, 也可以在客户端断开连接时自动释放.")]),t._v(" "),_("p",[t._v("在没出现更细粒度的锁之前, 表锁是常用的处理并发的方式, 但是对于InnoDB这种支持行锁的引擎来说, 不建议使用表锁, 毕竟锁整个表的影响太大.")]),t._v(" "),_("h5",{attrs:{id:"mdl锁-metadata-lock"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mdl锁-metadata-lock"}},[t._v("#")]),t._v(" MDL锁(metadata Lock)")]),t._v(" "),_("p",[t._v("在 MySQL 5.5 版本中引入了 MDL锁, MDL锁不需要显式的开启, 在访问一个表时会自动加上, 当对一个表做增删改查操作的时候, 加 MDL 读锁; 当要对表做结构变更操作的时候, 加 MDL 写锁.")]),t._v(" "),_("p",[_("strong",[t._v("注: 事务中的MDL锁, 会在语句开始执行的时候加上, 但是要等事务结束后才会释放.")])]),t._v(" "),_("h4",{attrs:{id:"行锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#行锁"}},[t._v("#")]),t._v(" 行锁")]),t._v(" "),_("p",[t._v("目前应该只有 InnoDB 引擎支持行锁, 这也是 MyISAM 被 InnoDB 取代的重要原因之一.")]),t._v(" "),_("p",[t._v("顾名思义, 行锁就是在数据行上加锁, 比如说, 线程A来更新数据, 加上了行锁, 那当线程B也来更新同一行时, 只能等待A完成后再执行更新操作.")]),t._v(" "),_("h5",{attrs:{id:"两阶段锁协议"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#两阶段锁协议"}},[t._v("#")]),t._v(" 两阶段锁协议")]),t._v(" "),_("p",[t._v("在 InnoDB 中, 行锁是在需要的时候加上, 但是要等到事务结束后再释放, 这就是两阶段锁协议.")]),t._v(" "),_("p",[_("strong",[t._v("建议: 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。")])]),t._v(" "),_("p",[_("strong",[t._v("注: MySQL行锁的最大并发数差不多是500左右.")])]),t._v(" "),_("h4",{attrs:{id:"间隙锁-gap-lock"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#间隙锁-gap-lock"}},[t._v("#")]),t._v(" 间隙锁(Gap Lock)")]),t._v(" "),_("p",[t._v("InnoDB 为了解决可重复读隔离级别下的幻读问题, 引入了间隙锁, 上文有提到过, 幻读就是说, 一个事务在执行过程中, 前后两次查询同一个范围的时候, 后一次查询看到了看到了原本不存在的行.")]),t._v(" "),_("p",[t._v('那这里额外说明一下, 因为可重复读隔离级别, 在启动事务的时候, 会开启一个快照, 所以它是看不到别的数据插入的行的, 所以, 幻读只会在"当前读"下才会发生.')]),t._v(" "),_("p",[t._v("顾名思义, 间隙锁就是说, 在两个值之间的空隙上加锁, 假设说一张表只有一个id字段, 一共有3条数据[1,2,3], 这张表就会有4个间隙, 即"),_("code",[t._v("(-∞~1), (1~2), (2~3), (3~+∞)")]),t._v(", 那当执行语句"),_("code",[t._v("select * from t for update")]),t._v("时, 不光会为三行记录加3个行锁, 同时也会为4个间隙加上间隙锁.")]),t._v(" "),_("p",[t._v('和读锁或者写锁不同, 间隙锁之间并不冲突, 可以有多个线程同时往同一个间隙上加锁, 和间隙锁冲突的是"要往这个间隙添加一条记录"这个动作.')]),t._v(" "),_("p",[t._v("引入间隙锁, 虽然可以解决幻读的问题, 但是, 它却降低了并发度, 因为它锁的范围更大, 举个栗子, 假设我们有这样一张表,")]),t._v(" "),_("div",{staticClass:"language-sql extra-class"},[_("pre",{pre:!0,attrs:{class:"language-sql"}},[_("code",[_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("t"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("b"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("c"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("d"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PRIMARY")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEY")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  UPIQUE "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEY")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("b"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("b"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEY")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("c"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("c"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ENGINE")]),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("InnoDB")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),_("p",[t._v("然后有两个线程要执行如下操作, 就会出现死锁, 因为两个session都在(5, 10)这个区间上加了间隙锁, session 2在执行insert语句的时候会被session 1的间隙锁block, 而session 1执行insert的时候, 会被session 2的间隙锁block, 就发生了死锁")]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",[t._v("session 1")]),t._v(" "),_("th",[t._v("session 2")])])]),t._v(" "),_("tbody",[_("tr",[_("td",[t._v("begin;"),_("br"),t._v("select * from t where id=9 for update;")]),t._v(" "),_("td")]),t._v(" "),_("tr",[_("td"),t._v(" "),_("td",[t._v("begin"),_("br"),t._v("select * from t where id=9 for update;")])]),t._v(" "),_("tr",[_("td"),t._v(" "),_("td",[t._v("insert into t values(9,9,9);"),_("br"),t._v("(这里会被block)")])]),t._v(" "),_("tr",[_("td",[t._v("insert into t values(9,9,9);"),_("br"),t._v("(这里就会出现死锁, deadlock found)")]),t._v(" "),_("td")])])]),t._v(" "),_("h4",{attrs:{id:"next-key-lock"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#next-key-lock"}},[t._v("#")]),t._v(" Next-key Lock")]),t._v(" "),_("p",[t._v("Next-Key Lock = 行锁+间隙锁, 是个前开后闭的区间, 而InnoDB在可重复读隔离级别下默认的加锁单位, 就是Next-key Lock.")]),t._v(" "),_("h3",{attrs:{id:"加锁逻辑"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#加锁逻辑"}},[t._v("#")]),t._v(" 加锁逻辑")]),t._v(" "),_("p",[t._v("首先, 要注意三点,")]),t._v(" "),_("ol",[_("li",[_("strong",[t._v("锁是加在索引上的")]),t._v(",")]),t._v(" "),_("li",[_("code",[t._v("lock in share mode")]),t._v("只锁覆盖索引(意思就是说, 如果满足覆盖索引的条件, 就不会到主键索引树上给访问到的行加锁), 如果要避免这一点, 就必须在查询时加入索引中没有的行,")]),t._v(" "),_("li",[_("code",[t._v("for update")]),t._v(", 使用这个语句, MySQL 会默认接下来要更新数据, 所以也会到主键索引树上加锁.")])]),t._v(" "),_("p",[t._v("下面, 借用一下"),_("a",{attrs:{href:"https://time.geekbang.org/column/article/75659",target:"_blank",rel:"noopener noreferrer"}},[t._v("MySQL实战45讲"),_("OutboundLink")],1),t._v("总结的 InnoDB 的加锁规则, 如下所示,")]),t._v(" "),_("p",[t._v("因为间隙锁是在可重复读隔离级别下才有效, 所以下面的加锁规则, 默认就是在可重复读下.")]),t._v(" "),_("ol",[_("li",[t._v("原则1, 加锁的基本单位是"),_("code",[t._v("Next-key Lock")]),t._v(", "),_("code",[t._v("Next-key Lock")]),t._v("是一个前开后闭的区间,")]),t._v(" "),_("li",[t._v("原则2, 查找过程中, 访问的到对象才会加锁,")]),t._v(" "),_("li",[t._v("优化1, 索引上的等值查询, 给唯一索引加锁时, "),_("code",[t._v("Next-key Lock")]),t._v("退化为行锁,")]),t._v(" "),_("li",[t._v("优化2, 索引上的等值查询, 向右遍历, 且最后一个值不满足等值条件时, "),_("code",[t._v("Next-key Lock")]),t._v("退化为间隙锁,")]),t._v(" "),_("li",[_("s",[t._v("1个bug")]),t._v(", 唯一索引上的范围查询, 会访问到不满足条件的第一个值为止.")])]),t._v(" "),_("p",[t._v("下面, 用上面的加锁规则来考虑一个问题, 即"),_("strong",[t._v("MySQL 的唯一索引, 非唯一索引, 无索引加锁有什么区别?")])]),t._v(" "),_("div",{staticClass:"language-sql extra-class"},[_("pre",{pre:!0,attrs:{class:"language-sql"}},[_("code",[_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* 主键索引 */")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" id "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" id "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" id "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* 唯一索引 */")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" b "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" b "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" b "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* 非唯一索引 */")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" c "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" c "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" c "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* 无索引 */")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" d "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" d "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" d "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("update")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),_("p",[t._v("参考上面的表t, 执行上面四条语句, 根据上面的加锁规则, 分别会加什么样的锁?")]),t._v(" "),_("ol",[_("li",[t._v("主键索引,\n"),_("ol",[_("li",[t._v("等值查询,\n"),_("ol",[_("li",[t._v("根据原则1, 加锁的基本单位是"),_("code",[t._v("next-key lock")]),t._v(", 所以会先给(0, 5]区间加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("同时根据优化1, 给唯一索引加锁时, "),_("code",[t._v("next-key lock")]),t._v("退化为行锁,")]),t._v(" "),_("li",[t._v("所以最终只会给主键索引树上id=5这一行加行锁.")])])]),t._v(" "),_("li",[t._v("区间查询,\n"),_("ol",[_("li",[t._v("根据原则1, 加锁的基本单位是"),_("code",[t._v("next-key lock")]),t._v(", 所以会先给(0, 5]区间加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("同时根据优化1, 给唯一索引加锁时, "),_("code",[t._v("next-key lock")]),t._v("退化为行锁,")]),t._v(" "),_("li",[t._v("因为是范围查询, 所以还要继续向后找, 找到第一个不满足条件的值为止, 所以会再给(5, 10]这个区间加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("所以最终会给主键索引树上的id=5加行锁, 给区间(5, 10]加"),_("code",[t._v("next-key lock")]),t._v(".")])])])])]),t._v(" "),_("li",[t._v("唯一索引,\n"),_("ol",[_("li",[t._v("等值查询,\n"),_("ol",[_("li",[t._v("根据原则1, 加锁的基本单位是"),_("code",[t._v("next-key lock")]),t._v(", 所以会先给(0, 5]区间加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("同时根据优化1, 唯一索引上的等值查询, "),_("code",[t._v("next-key lock")]),t._v("会退化为行锁,")]),t._v(" "),_("li",[t._v("所以最终会给b索引树上b=5这一行加上行锁, 由于是"),_("code",[t._v("for update")]),t._v(", 所以还会给主键索引树上的id=5这样加行锁.")])])]),t._v(" "),_("li",[t._v("区间查询, "),_("strong",[t._v("注意, 唯一索引的区间查询的示例和其他的不一样, 这个只是为了说明上文提到的"),_("s",[t._v("1个bug")])]),t._v(" "),_("ol",[_("li",[t._v("根据原则1, 加锁的基本单位是"),_("code",[t._v("next-key lock")]),t._v(", 所以会先给(5, 10]区间加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("因为是范围查询, 所以还要继续向后找, 直到扫描到第一个不满足条件的行为止, 也就是b=15, 所以还会给(10, 15]区间加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("所以, 最终会给b索引树上(5, 10], (10, 15]区间加"),_("code",[t._v("next-key lock")]),t._v(", 由于是"),_("code",[t._v("for update")]),t._v(",  所以主键索引树上扫描到的行, 都会加上行锁 , 在这里就是会给主键索引树上的id=10这一行加行锁, "),_("s",[t._v("id=15这一行没有加锁, 是因为这一行在b索引树上扫描到了, 但是不符合查询条件, 索引没有回到主键索引树扫描, 也就没有给这行加行锁")]),t._v(".")]),t._v(" "),_("li",[t._v("那这里, 因为是唯一索引, 所以当在b索引树上检索到b=15这一行时, 就可以停止了, 但是MySQL 还是会继续向下检索, 直到扫描到第一个不满足条件的行为止, "),_("s",[t._v("所以说这里可能会有一些小问题, 但是官方并没有说这个是bug, 所以就小声bb一下")]),t._v(".")])])])])]),t._v(" "),_("li",[t._v("非唯一索引,\n"),_("ol",[_("li",[t._v("等值查询,\n"),_("ol",[_("li",[t._v("根据原则1, 加锁的基本单位是"),_("code",[t._v("next-key lock")]),t._v(", 所以会先给(0, 5]区间加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("因为是普通索引, 所以还要向后遍历, 查到c=10时才停止, 此时根据原则2, 访问到的数据都要加锁, 所以会给(5, 10]加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("又根据优化2, 索引上的等值查询, 向右遍历且最后一个值不满足条件, "),_("code",[t._v("next-key lock")]),t._v("退化为间隙锁,")]),t._v(" "),_("li",[t._v("所以最终会给c索引树上的(0, 5], (5, 10)这两个区间加锁, 由于是"),_("code",[t._v("for update")]),t._v(", 所以主键索引树上扫描到的行, 都会加上行锁, 那在这里就会给id=5这一行加行锁.")])])]),t._v(" "),_("li",[t._v("区间查询,\n"),_("ol",[_("li",[t._v("根据原则1, 加锁的基本单位是"),_("code",[t._v("next-key lock")]),t._v(", 所以会先给(0, 5]区间加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("由于是普通索引, 所以"),_("code",[t._v("next-key lock")]),t._v("不会退化,")]),t._v(" "),_("li",[t._v("因为是范围查询, 所以还要继续向后找, 找到第一个不满足条件的值为止, 所以会再给(5, 10]这个区间加"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("所以最终会给c索引树上的(0, 5], (5, 10]这两个区间加"),_("code",[t._v("next-key lock")]),t._v(", 由于是"),_("code",[t._v("for update")]),t._v(", 所以主键索引树上扫描到的行, 都会加上行锁, 那在这里就会给id=5这一行加行锁.")])])])])]),t._v(" "),_("li",[t._v("无索引,\n"),_("ol",[_("li",[t._v("等值查询,\n"),_("ol",[_("li",[t._v("因为没有索引, 所以要进行全表扫描, 根据原则1, 加锁的基本单位是"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("根据原则2, 访问到的对象都要加锁,")]),t._v(" "),_("li",[t._v("所以最终会锁住整个主键索引树, 即(-∞, 0], (0, 5], (5,10], (10, 15], (15, 20], (20, 25], (25, super]全都会加上锁.")])])]),t._v(" "),_("li",[t._v("区间查询,\n"),_("ol",[_("li",[t._v("因为没有索引, 所以要进行全表扫描, 根据原则1, 加锁的基本单位是"),_("code",[t._v("next-key lock")]),t._v(",")]),t._v(" "),_("li",[t._v("根据原则2, 访问到的对象都要加锁,")]),t._v(" "),_("li",[t._v("所以最终会锁住整个主键索引树, 即(-∞, 0], (0, 5], (5,10], (10, 15], (15, 20], (20, 25], (25, super]全都会加上锁.")])])])])])]),t._v(" "),_("h3",{attrs:{id:"对比-3"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#对比-3"}},[t._v("#")]),t._v(" 对比")]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",[t._v("存储引擎")]),t._v(" "),_("th",[t._v("InnoDB")]),t._v(" "),_("th",[t._v("myisam")])])]),t._v(" "),_("tbody",[_("tr",[_("td",[t._v("全局锁")]),t._v(" "),_("td",[t._v("✅")]),t._v(" "),_("td",[t._v("✅")])]),t._v(" "),_("tr",[_("td",[t._v("表级锁")]),t._v(" "),_("td",[t._v("✅")]),t._v(" "),_("td",[t._v("✅")])]),t._v(" "),_("tr",[_("td",[t._v("行锁")]),t._v(" "),_("td",[t._v("✅")]),t._v(" "),_("td",[t._v("❌")])])])]),t._v(" "),_("h3",{attrs:{id:"死锁和死锁检测"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#死锁和死锁检测"}},[t._v("#")]),t._v(" 死锁和死锁检测")]),t._v(" "),_("p",[t._v("当并发系统中不同线程出现循环资源依赖, 涉及的线程都在等待别的线程释放资源时, 就会导致这几个线程都进入无限等待的状态, 称为死锁.")]),t._v(" "),_("p",[t._v("假设, 有一个事务A在等待事务B释放id=1上的行锁, 而事务B在等待事务A释放id=2上的行锁, 两个事务都在互相等待对方的资源释放, 这时就是死锁状态.  这个时候, 我们有两种解决策略:")]),t._v(" "),_("ul",[_("li",[t._v("一种是直接进入等待, 直到超时, 我们可以通过参数innodb_lock_wait_timeout来设置超时时间, 默认是50s.")]),t._v(" "),_("li",[t._v("另一种是发起死锁检测, 当发现死锁后, 主动回滚死锁链条中的某一个事务, 让其他事务可以继续执行, 将参数innodb_deadlock_detect设置为on, 代表开启这个逻辑.\n超时等待有一个弊端, 就是我们不清楚到底应该设置为多少, 默认的50s显然是太长的, 如果是在线服务, 这个等待时间是无法接受的; 但是如果设置的比较短, 就会导致, 如果只是一个简单的锁等待, 太短的等待时间会导致我们正常的业务逻辑受影响.\n所以, 一般情况下, 我们会选择第二种策略, 即主动死锁检测, 而且, 它也是默认打开的.\n但是, 死锁检测也是有额外负担的, 如果说我们有很多线程对同一行数据进行更新, 那每个新来的线程都需要判断会不会导致死锁, 这样就会引入额外的时间复杂度, 就会消耗大量的CPU资源, 导致CPU利用率飙升, 但是却没执行多少事务.\n对于上述死锁检测的问题, 我们大概有几种思路:")]),t._v(" "),_("li",[t._v("关闭死锁检测, 缺点是, 一旦出现死锁, 就意味着大量的超时, 这对我们的业务是有影响的, 治标不治本的方式, 不建议.")]),t._v(" "),_("li",[t._v("控制并发度, 即在客户端做控制, 同一行同一时间只允许几个线程进行修改, 缺点是, 如果客户端很多, 一样会导致修改的线程很多, 导致并发增高, 同样也是治标不治本, 但是如果客户端连接很少, 可以考虑.")]),t._v(" "),_("li",[t._v("在服务端进行并发控制, 如果有中间件, 可以在中间件层实现, "),_("s",[t._v("如果没有, 也可以修改MySQL的源码, 在MySQL里进行控制, 理论上我们使用队列, 将请求queue起来, 就能解决这个问题, 缺点是, 对技术要求较高, 需要有能修改MySQL源码的人参与")]),t._v(".")]),t._v(" "),_("li",[t._v("一行数据变多行, 减少锁冲突, 将请求的线程随机选一条数据进行修改, 这样的话, 冲突概率就可以减少, 缺点是, 需要业务代码做额外的处理, 在查询时要将多行数据合为一行.\n其实, 综上来看, 我们可以发现, 减少死锁的主要思路, 就是要控制访问相同资源并发数量.")])]),t._v(" "),_("h2",{attrs:{id:"查询优化"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#查询优化"}},[t._v("#")]),t._v(" 查询优化")]),t._v(" "),_("p",[t._v("首先, 涉及到SQL优化, 那肯定少不了通过explain语句分析select查询语句, 所以, 先简单了解下, explain语句的返回列的含义.")]),t._v(" "),_("table",[_("thead",[_("tr",[_("th",[t._v("列")]),t._v(" "),_("th",[t._v("含义")]),t._v(" "),_("th",[t._v("返回值的含义")])])]),t._v(" "),_("tbody",[_("tr",[_("td",[_("strong",[t._v("select_type")])]),t._v(" "),_("td",[t._v("查询类型")]),t._v(" "),_("td",[_("strong",[t._v("simple")]),t._v(", 简单查询,"),_("br"),_("strong",[t._v("union")]),t._v(", 联合查询,"),_("br"),_("strong",[t._v("subquery")]),t._v(", 子查询.")])]),t._v(" "),_("tr",[_("td",[t._v("table")]),t._v(" "),_("td",[t._v("要查询的表")]),t._v(" "),_("td")]),t._v(" "),_("tr",[_("td",[t._v("possible_keys")]),t._v(" "),_("td",[t._v("可选择的索引")]),t._v(" "),_("td")]),t._v(" "),_("tr",[_("td",[t._v("key")]),t._v(" "),_("td",[t._v("使用的索引")]),t._v(" "),_("td")]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("type")])]),t._v(" "),_("td",[t._v("索引查询类型")]),t._v(" "),_("td",[_("strong",[t._v("system")]),t._v(", 表只有这一行数据, const的特殊情况,"),_("br"),_("strong",[t._v("const")]),t._v(", 使用主键或者唯一索引查询时, 只有一行返回,"),_("br"),_("strong",[t._v("eq_ref")]),t._v(", 进行联合查询时, 使用主键或者唯一索引, 并且只返回了一行数据,"),_("br"),_("strong",[t._v("ref")]),t._v(", 使用非唯一索引查询时, "),_("br"),_("strong",[t._v("range")]),t._v(", 使用主键, 单个字段的辅助索引, 多个字段的辅助索引的最后一个字段, 进行范围查询时,"),_("br"),_("strong",[t._v("index")]),t._v(", 和all的区别是, 1) 查询的字段是索引的一部分, 覆盖索引, 2) 使用主键进行排序,"),_("br"),_("strong",[t._v("all")]),t._v(", 全表扫描.")])]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("ref")])]),t._v(" "),_("td"),t._v(" "),_("td")]),t._v(" "),_("tr",[_("td",[t._v("rows")]),t._v(" "),_("td",[t._v("扫描的行数")]),t._v(" "),_("td",[t._v("预估值, 并不准确, 但是越小越好.")])]),t._v(" "),_("tr",[_("td",[_("strong",[t._v("Extra")])]),t._v(" "),_("td"),t._v(" "),_("td")])])]),t._v(" "),_("h3",{attrs:{id:"一些优化思路"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#一些优化思路"}},[t._v("#")]),t._v(" 一些优化思路")]),t._v(" "),_("ol",[_("li",[t._v("减少请求的数据量,\n"),_("ol",[_("li",[t._v("查询时, 返回指定的列, 尽量避免使用"),_("code",[t._v("select * from xxx")]),t._v("语句,")]),t._v(" "),_("li",[t._v("只返回必要的行数, 使用limit语句限制返回的行数,")]),t._v(" "),_("li",[t._v("对大表进行分页查询时, 不要使用limit n, offset m语句, 如果可以的话, 带着id进行查询, 没有id, 那就先查询出id, 再根据id查询数据行.")])])]),t._v(" "),_("li",[t._v("优先使用覆盖索引, 避免回表查询,")]),t._v(" "),_("li",[t._v("使用联合索引查询时, 注意最左前缀的要求, 且索引的使用可以乱序")]),t._v(" "),_("li",[t._v("如果需要使用join语句, 以小表(这里的小表说的是, 符合where条件的数据行比较少的表)作为驱动表, 同时, 建议给被驱动表的关联字段加上索引,")]),t._v(" "),_("li",[t._v("分解大查询, 可以将一个大的连接查询, 分解成多个单表查询, 然后应用程序中进行关联.")])]),t._v(" "),_("h3",{attrs:{id:"其他优化"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#其他优化"}},[t._v("#")]),t._v(" 其他优化")]),t._v(" "),_("ol",[_("li",[t._v("count(*), count(1)和count(id)的区别.\n"),_("ol",[_("li",[t._v("对于count(*)来说, InnoDB 会遍历整张表, 但是不取值, server层对于返回的每一行, 按行累加, 下面是官网原话,")]),t._v(" "),_("li",[t._v('对于count(1)来说, InnoDB 会遍历整张表, 但是不取值, server层对于返回的每一行, 放一个数字"1"进去, 然后判断不为空, 再按行累加,\n下面是官方文档原话,\n'),_("code",[t._v("InnoDB")]),t._v(" processes "),_("code",[t._v("SELECT COUNT(*)")]),t._v(" statements by traversing the smallest available secondary index unless an index or optimizer hint directs the optimizer to use a different index. If a secondary index is not present, the clustered index is scanned.\n"),_("code",[t._v("InnoDB")]),t._v(" handles "),_("code",[t._v("SELECT COUNT(*)")]),t._v(" and "),_("code",[t._v("SELECT COUNT(1)")]),t._v(" operations in the same way. There is no performance difference.\n就是说, count(*)和count(1)都会优先扫描索引树较小的二级索引树来进行统计, 如果没有二级索引, 才会扫描主键索引, 所以二者的性能是差不多的.")]),t._v(" "),_("li",[t._v("对于count(id)来说, InnoDB 会遍历整张表, 把每一行的id值都取出来, 返回给server层, server层拿到id后, 判断不为空, 然后按行累加,")]),t._v(" "),_("li",[t._v("对于count(field)来说, 和count(id)类似, InnoDB 会遍历整张表, 把每一行的field值都取出来, 判断不为空, 然后按行累加,")]),t._v(" "),_("li",[t._v("所以, 可以得出结论, 在查询效率上, "),_("code",[t._v("count(*)=count(1)>count(id)>count(field)")]),t._v(",")]),t._v(" "),_("li",[t._v("这里还有个特殊的地方, 就是 myisam 存储引擎是有特殊优化的, 如果是"),_("code",[t._v("select count(*) from t")]),t._v("这种查询的话, myisam会非常快, 因为它存储了表准确的行数, 但是如果是带有"),_("code",[t._v("where")]),t._v("查询的"),_("code",[t._v("select count(*)")]),t._v(", myisam也是需要扫描的,")]),t._v(" "),_("li",[t._v("而 InnoDB 因为 MVCC 的存在, 没办法保存表的准确行数, 每次都要进行扫描,")]),t._v(" "),_("li",[t._v("如果只需要获取表的近似行数, 也可以使用"),_("code",[t._v("show table status")]),t._v("命令.")])])])]),t._v(" "),_("h2",{attrs:{id:"分库分表"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分库分表"}},[t._v("#")]),t._v(" 分库分表")]),t._v(" "),_("h3",{attrs:{id:"垂直切分"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#垂直切分"}},[t._v("#")]),t._v(" 垂直切分")]),t._v(" "),_("p",[t._v("一般都是根据业务来切分, 现在都是微服务开发, 每个系统都有各自的DB, 每个系统各自持久化数据.")]),t._v(" "),_("h3",{attrs:{id:"水平切分"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#水平切分"}},[t._v("#")]),t._v(" 水平切分")]),t._v(" "),_("p",[t._v("将数据量很大的表进行水平切分, 每个表的结构都是一样的, 以此来解决单个表的数据量上限的问题.")]),t._v(" "),_("h3",{attrs:{id:"问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#问题"}},[t._v("#")]),t._v(" 问题")]),t._v(" "),_("h4",{attrs:{id:"分布式事务"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式事务"}},[t._v("#")]),t._v(" 分布式事务")]),t._v(" "),_("p",[t._v("无论是垂直分还是水平分, 都会涉及到多个系统之间的配合, 那如果一个业务需要多个系统进行配合, 而且还要满足事务的特性, 就肯定会涉及到分布式事务.")]),t._v(" "),_("p",[t._v("现有的分布式事务解决方案有很多, 像XA协议的有2pc, 3pc, 或者一些柔性事务的有tcc, saga, 消息最终一致性等等, 之后会有一片专门的分布式事务的文章, 在这里就先不赘述了.")]),t._v(" "),_("h4",{attrs:{id:"跨库join"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#跨库join"}},[t._v("#")]),t._v(" 跨库join")]),t._v(" "),_("p",[t._v("以前是只有一个DB, 所有的join可以使用一个select语句完成(当然, 超多表的join也不推荐使用), 现在有多个DB, 如果联查多个库的多张表, 就会涉及到跨库join.")]),t._v(" "),_("p",[t._v("那一般都会考虑, 将原来的多表查询分解成多个单表查询, 拿到返回数据后在用户程序中进行连接, 而且, 也要注意尽量避免超大数据量的查询, 可能会导致用户程序的使用内存暴增.")]),t._v(" "),_("h4",{attrs:{id:"sharding策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#sharding策略"}},[t._v("#")]),t._v(" sharding策略")]),t._v(" "),_("p",[t._v("sharing策略其实就是水平切分的策略了, 什么样的数据路由到哪个DB, 那一般有如下几种常用的策略,")]),t._v(" "),_("ol",[_("li",[t._v("hash取模, 比如说根据某一个唯一key, 进行hash(key)/%N, 这里的N就是分表的数量, 这种方式最简单, 但是问题也很明显, 如果以后要扩展分表的数量, 就需要进行表数据迁移.")]),t._v(" "),_("li",[t._v("范围切分, 可以根据ID也可以根据时间, 举个栗子,\n"),_("ol",[_("li",[t._v("如果数据量很大的话, 那可以每个月分一张表, 这样就不会有扩展上的问题, 因为时间是一直向前的, 类似于订单类型的数据, 可以考虑使用这种方式, 然后提供给用户查询时, 可以把查询条件限制为时间维度, 比如说查询"),_("code",[t._v("2020-10")]),t._v("这个月的数据, 那可以路由到该月的DB去查询.")])])]),t._v(" "),_("li",[t._v("映射表, 其实就是通过一个单独的数据库来维护路由规则.")])]),t._v(" "),_("h4",{attrs:{id:"数据唯一性"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据唯一性"}},[t._v("#")]),t._v(" 数据唯一性")]),t._v(" "),_("p",[t._v("唯一性就是说, 同一个表的每条记录肯定要有个唯一的ID嘛, 那有以下几种思路,")]),t._v(" "),_("ol",[_("li",[_("s",[t._v("UUID")]),t._v(", 不建议使用,")]),t._v(" "),_("li",[t._v("使用全局唯一 ID(GUID), 比如说可以有一个专门生成ID的服务,")]),t._v(" "),_("li",[t._v("为每个分片指定一个ID范围,")]),t._v(" "),_("li",[t._v("分布式ID生成器, 比如雪花算法这种.")])]),t._v(" "),_("h2",{attrs:{id:"高可用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#高可用"}},[t._v("#")]),t._v(" 高可用")]),t._v(" "),_("p",[_("s",[t._v("肝不动了, 下次补上.")])]),t._v(" "),_("h3",{attrs:{id:"主从复制"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#主从复制"}},[t._v("#")]),t._v(" 主从复制")]),t._v(" "),_("h3",{attrs:{id:"读写分离"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#读写分离"}},[t._v("#")]),t._v(" 读写分离")]),t._v(" "),_("h2",{attrs:{id:"一些常用命令"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#一些常用命令"}},[t._v("#")]),t._v(" 一些常用命令")]),t._v(" "),_("div",{staticClass:"language-sql extra-class"},[_("pre",{pre:!0,attrs:{class:"language-sql"}},[_("code",[_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* 重建表*/")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("alter")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" t "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("engine")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("InnoDB")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* 可以用来重新统计索引信息 */")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("analyze")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" t"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* 等于 recreate + analyze */")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("optimize")]),t._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" t"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* 等于 drop + create */")]),t._v("\ntruntace "),_("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" t"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),_("h2",{attrs:{id:"数据库的三范式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据库的三范式"}},[t._v("#")]),t._v(" 数据库的三范式")]),t._v(" "),_("ol",[_("li",[t._v("第一范式: 列不可再分,")]),t._v(" "),_("li",[t._v("第二范式: 行可以唯一区分, 主键约束,")]),t._v(" "),_("li",[t._v("第三范式: 表的非主属性不能依赖与其他表的非主属性, 外键约束,")]),t._v(" "),_("li",[t._v("三大范式是一级一级依赖的, 第二范式建立在第一范式上, 第三范式建立第一第二范式上.")])]),t._v(" "),_("h2",{attrs:{id:"参考"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#参考"}},[t._v("#")]),t._v(" 参考")]),t._v(" "),_("ul",[_("li",[t._v("高性能MySQL")]),t._v(" "),_("li",[_("a",{attrs:{href:"https://dev.mysql.com/doc/refman/5.7/en/",target:"_blank",rel:"noopener noreferrer"}},[t._v("MySQL 5.7 Reference Manual"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://time.geekbang.org/column/intro/139",target:"_blank",rel:"noopener noreferrer"}},[t._v("MySQL实战45讲"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://tech.meituan.com/2014/06/30/mysql-index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("MySQL索引原理及慢查询优化"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://mp.weixin.qq.com/s/faOaXRQM8p0kwseSHaMCbg",target:"_blank",rel:"noopener noreferrer"}},[t._v("一口气搞懂MySQL索引所有知识点"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://mp.weixin.qq.com/s/J3kCOJwyv2nzvI0_X0tlnA",target:"_blank",rel:"noopener noreferrer"}},[t._v("国庆肝了8天整整2W字的数据库知识点"),_("OutboundLink")],1)])])])}),[],!1,null,null,null);s.default=v.exports}}]);